import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime

try:
    from thefuzz import fuzz
except ImportError:
    st.error("Hi√°nyzik: pip install thefuzz python-Levenshtein")
    st.stop()

import io

# ============================================================================
# üé® HYPER App - Neuromarketing ROAS Predictor v3.7
# F√ÅZIS 1: CSV Importer & Intelligent Mapper
# ============================================================================

st.set_page_config(
    page_title="HYPER - Marketing Predictor",
    page_icon="üéØ",
    layout="wide",
    initial_sidebar_state="expanded",
)

# ============================================================================
# üìä CONFIGURATION & MAPPINGS (Excel alapj√°n)
# ============================================================================

UNIFIED_SCHEMA = {
    "mandatory": [
        ("date_start", "date", "Jelent√©s kezdete (d√°tum)"),
        ("date_end", "date", "Jelent√©s v√©ge (d√°tum)"),
        ("campaign_name", "string", "Kamp√°ny neve"),
        ("platform", "string", "Platform (Facebook/Google Ads/TikTok)"),
        ("campaign_status", "string", "Kamp√°ny st√°tusza"),
        ("spend", "float", "Elk√∂lt√∂tt √∂sszeg (HUF)"),
        ("conversions", "int", "Konverzi√≥k / V√°s√°rl√°sok"),
        ("conversion_value", "float", "Konverzi√≥s √©rt√©k (HUF)"),
    ],
    "recommended": [
        ("impressions", "int", "Megjelen√©sek"),
        ("clicks", "int", "Kattint√°sok / Interakci√≥k"),
        ("ctr_percent", "float", "CTR (%)"),
        ("cpc", "float", "CPC (HUF)"),
        ("cpa", "float", "CPA (HUF, sz√°m√≠tott)"),
        ("conv_cost", "float", "Konverzi√≥s k√∂lts√©g (HUF)"),
        ("roas", "float", "ROAS (x)"),
        ("reach", "int", "El√©r√©s"),
        ("frequency", "float", "Gyakoris√°g"),
        ("add_to_cart", "int", "Kos√°rba helyez√©sek"),
        ("cost_per_addtocart", "float", "Kos√°rba helyez√©s egys√©gnyi k√∂lts√©ge (HUF)"),
        ("results", "int", "Eredm√©nyek (FB results oszlop)"),
        ("adset_budget", "float", "Hirdet√©ssorozat k√∂lts√©gkerete (HUF)"),
        ("adset_budget_type", "string", "Hirdet√©ssorozat k√∂lts√©gkeret√©nek t√≠pusa"),
    ],
    "optional": [
        ("video_views", "int", "Vide√≥ megtekint√©sek"),
        ("engagement", "int", "Engagement"),
        ("notes", "string", "Megjegyz√©sek"),
    ],
}

# Excel: CSV Oszlop ‚Üí Unified Field + javasolt param√©terek[file:39]
COLUMN_PATTERNS = {
    # 0  | CPC (√∂sszes) (HUF)                     | cpc                     |
    "cpc": ["cpc (√∂sszes)", "cpc (√∂sszes) (huf)", "cpc", "cost per click"],

    # 1  | CTR (√°tkattint√°si ar√°ny)              | clicks | ctr            |
    # Itt a unified field val√≥j√°ban CTR ‚Üí ctr_percent, a bels≈ë param√©ter a "ctr"
    "ctr_percent": ["ctr (√°tkattint√°si ar√°ny)", "ctr", "√°tkattint√°si ar√°ny"],

    # 2  | Elk√∂lt√∂tt √∂sszeg (HUF)                | spend   | all_spend      |
    "spend": ["elk√∂lt√∂tt √∂sszeg (huf)", "elk√∂lt√∂tt √∂sszeg", "spend", "amount spent"],

    # 3  | El√©r√©s                                | reach                   |
    "reach": ["el√©r√©s", "reach"],

    # 4  | Eredm√©ny jelz√©se                      | conv_cost | (nem kell)   |
    # Nem haszn√°ljuk normaliz√°l√°shoz, ez√©rt nem adunk neki unified fieldet.

    # 5  | Eredm√©nyek                            | conv_cost | results      |
    # Itt a unified field "results" (darabsz√°m), a param√©ter "results".
    "results": ["eredm√©nyek", "results"],

    # 6  | Eredm√©nyenk√©nti k√∂lts√©g               | spend    | cost_per_result
    # Val√≥j√°ban konverzi√≥s k√∂lts√©g ‚Üí conv_cost.
    "conv_cost": ["eredm√©nyenk√©nti k√∂lts√©g", "cost per result"],

    # 7  | Gyakoris√°g                            | frequency              |
    "frequency": ["gyakoris√°g", "frequency"],

    # 8  | Hirdet√©ssorozat k√∂lts√©gkerete         | spend    | adset_cost   |
    "adset_budget": ["hirdet√©ssorozat k√∂lts√©gkerete", "adset budget"],

    # 9  | Hirdet√©ssorozat k√∂lts√©gkeret√©nek t√≠pusa | spend |               |
    "adset_budget_type": ["hirdet√©ssorozat k√∂lts√©gkeret√©nek t√≠pusa", "budget type"],

    # 10 | Jelent√©s kezdete                      | date_start             |
    "date_start": ["jelent√©s kezdete", "report start", "start date"],

    # 11 | Jelent√©s v√©ge                         | date_end               |
    # 21 | V√©ge                                  | date_end               |
    "date_end": ["jelent√©s v√©ge", "v√©ge", "report end", "end date"],

    # 12 | Kamp√°ny neve                          | campaign_name          |
    "campaign_name": ["kamp√°ny neve", "campaign name", "campaign"],

    # 13 | Kamp√°ny teljes√≠t√©se                   | campaign_status        |
    "campaign_status": ["kamp√°ny teljes√≠t√©se", "status", "√°llapot"],

    # 14 | Kos√°rba helyez√©s egys√©gnyi k√∂lts√©ge (HUF) | spend | cost_per_addtocart
    "cost_per_addtocart": [
        "kos√°rba helyez√©s egys√©gnyi k√∂lts√©ge",
        "kos√°rba helyez√©s egys√©gnyi k√∂lts√©ge (huf)",
        "cost per add to cart",
    ],

    # 15 | Kos√°rba helyez√©sek                    | add_to_cart           |
    "add_to_cart": ["kos√°rba helyez√©sek", "add to cart"],

    # 16 | Kos√°rba helyez√©sek konverzi√≥s √©rt√©ke  | conversion_value | addtocart_value
    # Ez is konverzi√≥s √©rt√©k, de add_to_cart t√≠pushoz; alap unified field: conversion_value.
    "conversion_value": [
        "kos√°rba helyez√©sek konverzi√≥s √©rt√©ke",
        "v√°s√°rl√°sok konverzi√≥s √©rt√©ke",
        "purchase value",
        "conversion value",
        "bev√©tel",
    ],

    # 17 | Megjelen√©sek                          | impressions           |
    "impressions": ["megjelen√©sek", "impressions"],

    # 18 | V√°s√°rl√°si hirdet√©smegt√©r√ºl√©s (ROAS)   | roas                  |
    "roas": ["v√°s√°rl√°si hirdet√©smegt√©r√ºl√©s", "roas", "hirdet√©smegt√©r√ºl√©s"],

    # 19 | V√°s√°rl√°sok                            | conversions | purchase  |
    "conversions": ["v√°s√°rl√°sok", "konverzi√≥k", "purchases", "orders"],

    # 20 | V√°s√°rl√°sok konverzi√≥s √©rt√©ke          | conversions | purchase_value
    # Itt az Excelben unified field hib√°s volt; itt is conversion_value‚Äënak feleltetj√ºk meg.
    # (M√°r bent van a conversion_value list√°ban.)
    # 21 | V√©ge                                  | date_end              |
    # -> date_end list√°ban m√°r szerepel.
}

# ============================================================================
# üîß HELPER FUNCTIONS
# ============================================================================

def find_matching_column(csv_column, patterns_dict, threshold=70):
    csv_col_lower = csv_column.lower().strip()
    best_match = None
    best_score = 0
    for unified_field, patterns in patterns_dict.items():
        for pattern in patterns:
            score = fuzz.partial_ratio(csv_col_lower, pattern.lower())
            if score > best_score:
                best_score = score
                best_match = unified_field
    if best_score >= threshold:
        return best_match, best_score
    return None, best_score


def intelligently_map_columns(df_columns):
    mapping = {}
    unmapped = []
    for col in df_columns:
        matched_field, score = find_matching_column(col, COLUMN_PATTERNS)
        if matched_field:
            mapping[col] = matched_field
        else:
            unmapped.append(col)
    return mapping, unmapped


def parse_numeric_value(val):
    if pd.isna(val) or val == "" or val == "‚Äì" or val == "--":
        return np.nan
    if isinstance(val, (int, float)):
        return float(val)
    s = str(val).strip()
    s = s.replace("\u00a0", "").replace(" ", "")
    if "," in s and "." in s:
        s = s.replace(".", "").replace(",", ".")
    else:
        s = s.replace(",", ".")
    try:
        return float(s)
    except Exception:
        return np.nan


def parse_percentage_value(val):
    if pd.isna(val) or val == "" or val == "‚Äì":
        return np.nan
    s = str(val).strip().replace("%", "")
    s = s.replace("\u00a0", "").replace(" ", "")
    if "," in s and "." in s:
        s = s.replace(".", "").replace(",", ".")
    else:
        s = s.replace(",", ".")
    try:
        return float(s)
    except Exception:
        return np.nan


def parse_date(val):
    if pd.isna(val):
        return None
    date_formats = [
        "%Y-%m-%d",
        "%Y.%m.%d",
        "%d.%m.%Y",
        "%d-%m-%Y",
        "%m/%d/%Y",
    ]
    for fmt in date_formats:
        try:
            return pd.to_datetime(val, format=fmt)
        except Exception:
            continue
    try:
        return pd.to_datetime(val)
    except Exception:
        return None


def normalize_data(df, mapping, user_adjustments=None, platform_hint=None):
    if user_adjustments:
        mapping = {**mapping, **user_adjustments}

    normalized_df = pd.DataFrame()

    for csv_col, unified_col in mapping.items():
        if csv_col not in df.columns:
            continue

        field_info = None
        for section in [UNIFIED_SCHEMA["mandatory"], UNIFIED_SCHEMA["recommended"], UNIFIED_SCHEMA["optional"]]:
            for field in section:
                if field[0] == unified_col:
                    field_info = field
                    break

        if not field_info:
            continue

        field_name, field_type, _ = field_info
        raw_data = df[csv_col]

        if field_name == "ctr_percent":
            normalized_df[field_name] = raw_data.apply(parse_percentage_value)
        elif field_type == "float":
            normalized_df[field_name] = raw_data.apply(parse_numeric_value)
        elif field_type == "int":
            normalized_df[field_name] = raw_data.apply(
                lambda x: int(parse_numeric_value(x))
                if not pd.isna(parse_numeric_value(x))
                else np.nan
            )
        elif field_type == "date":
            normalized_df[field_name] = raw_data.apply(parse_date)
        elif field_type == "string":
            normalized_df[field_name] = raw_data.astype(str)
        else:
            normalized_df[field_name] = raw_data

    if "date_start" in normalized_df.columns and "date_end" not in normalized_df.columns:
        normalized_df["date_end"] = normalized_df["date_start"]

    if "platform" not in normalized_df.columns:
        normalized_df["platform"] = platform_hint if platform_hint else "Unknown"

    if "spend" in normalized_df.columns and "conversion_value" in normalized_df.columns:
        if "roas" not in normalized_df.columns:
            normalized_df["roas"] = normalized_df["conversion_value"] / normalized_df["spend"]
            normalized_df["roas"] = normalized_df["roas"].replace([np.inf, -np.inf], np.nan)

    if "spend" in normalized_df.columns and "conversions" in normalized_df.columns:
        if "cpa" not in normalized_df.columns:
            normalized_df["cpa"] = normalized_df["spend"] / normalized_df["conversions"]
            normalized_df["cpa"] = normalized_df["cpa"].replace([np.inf, -np.inf], np.nan)

    if "clicks" in normalized_df.columns and "impressions" in normalized_df.columns:
        if "ctr_percent" not in normalized_df.columns:
            normalized_df["ctr_percent"] = (
                normalized_df["clicks"] / normalized_df["impressions"] * 100
            )
            normalized_df["ctr_percent"] = normalized_df["ctr_percent"].replace(
                [np.inf, -np.inf], np.nan
            )

    if "spend" in normalized_df.columns and "clicks" in normalized_df.columns:
        if "cpc" not in normalized_df.columns:
            normalized_df["cpc"] = normalized_df["spend"] / normalized_df["clicks"]
            normalized_df["cpc"] = normalized_df["cpc"].replace([np.inf, -np.inf], np.nan)

    return normalized_df


def validate_data(df):
    issues = []
    mandatory_fields = [f[0] for f in UNIFIED_SCHEMA["mandatory"]]
    for field in mandatory_fields:
        if field not in df.columns:
            issues.append(f"‚ùå Hi√°nyzik: {field}")
        elif df[field].isna().sum() > len(df) * 0.5:
            issues.append(f"‚ö†Ô∏è T√∫l sok hi√°nyzik: {field} ({df[field].isna().sum()} / {len(df)})")

    if "roas" in df.columns:
        invalid_roas = df[(df["roas"] < 0) | (df["roas"] > 100)].shape[0]
        if invalid_roas > 0:
            issues.append(f"‚ö†Ô∏è √ârv√©nytelen ROAS √©rt√©kek: {invalid_roas}")

    if "cpa" in df.columns:
        invalid_cpa = df[(df["cpa"] < 0)].shape[0]
        if invalid_cpa > 0:
            issues.append(f"‚ö†Ô∏è Negat√≠v CPA √©rt√©kek: {invalid_cpa}")

    return issues


# ============================================================================
# üé® STREAMLIT UI
# ============================================================================

st.title("üéØ HYPER - Marketing Campaign Analyzer")
st.markdown("## F√°zis 1: Intelligens CSV Importer")

if "uploaded_data" not in st.session_state:
    st.session_state.uploaded_data = None
if "mapping" not in st.session_state:
    st.session_state.mapping = {}
if "normalized_data" not in st.session_state:
    st.session_state.normalized_data = None

tab1, tab2, tab3, tab4 = st.tabs(
    ["üì• Felt√∂lt√©s & Mapping", "‚úÖ Valid√°ci√≥", "üìä El≈ën√©zet", "üíæ Ment√©s"]
)

# ---------------------------------------------------------------------------
# TAB 1 ‚Äì Felt√∂lt√©s & Mapping
# ---------------------------------------------------------------------------
with tab1:
    col1, col2 = st.columns([2, 1])

    with col1:
        st.subheader("1Ô∏è‚É£ CSV/Excel Felt√∂lt√©s")
        uploaded_file = st.file_uploader(
            "V√°lassz CSV vagy Excel f√°jlt",
            type=["csv", "xlsx", "xls"],
            help="Facebook, Google Ads vagy TikTok export",
        )

    with col2:
        st.subheader("‚ÑπÔ∏è T√°mogatott form√°tumok")
        st.markdown(
            """
        - ‚úÖ Facebook Ads Manager
        - ‚úÖ Google Ads
        - ‚è≥ TikTok (hamarosan)
        """
        )

    platform_hint = st.selectbox(
        "Melyik platformr√≥l sz√°rmazik ez a f√°jl?",
        ["Facebook", "Google Ads", "TikTok", "Ismeretlen"],
        index=0,
        help="Ez beker√ºl a 'platform' oszlopba, ha a CSV-ben nincs ilyen mez≈ë.",
    )

    if uploaded_file:
        try:
            if uploaded_file.name.endswith(".csv"):
                raw_df = pd.read_csv(uploaded_file, encoding="utf-8-sig")
            else:
                raw_df = pd.read_excel(uploaded_file)

            st.session_state.uploaded_data = raw_df

            st.success(f"‚úÖ Bet√∂ltve: {uploaded_file.name}")
            st.info(f"üìä Sorok: {len(raw_df)}, Oszlopok: {len(raw_df.columns)}")

            st.subheader("2Ô∏è‚É£ Automata Oszlop Felismer√©s")
            initial_mapping, unmapped = intelligently_map_columns(raw_df.columns)
            st.session_state.mapping = initial_mapping

            st.markdown("#### üîÑ Automatikusan felismert oszlopok:")
            mapped_cols = st.expander("‚úÖ Lek√©pezett oszlopok", expanded=True)
            with mapped_cols:
                mapping_display = [
                    {"CSV Oszlop": csv_col, "Unified Field": unified_col}
                    for csv_col, unified_col in sorted(initial_mapping.items())
                ]
                if mapping_display:
                    st.dataframe(pd.DataFrame(mapping_display), use_container_width=True)
                else:
                    st.warning("Nincs automata felismer√©s :(")

            if unmapped:
                unmapped_cols = st.expander(f"‚ö†Ô∏è Felismeretlen oszlopok ({len(unmapped)})")
                with unmapped_cols:
                    st.warning("A k√∂vetkez≈ë oszlopok nem ker√ºltek besorol√°sra:")
                    for col in unmapped:
                        st.text(f"‚Ä¢ {col}")

            st.subheader("3Ô∏è‚É£ Manu√°lis Korrekci√≥ (opcion√°lis)")
            st.markdown("Ha valamelyik mez≈ë rossz helyre ker√ºlt, itt tudod jav√≠tani.")

            manual_corrections = {}
            all_fields = ["--Nincs--"]
            for section in [
                UNIFIED_SCHEMA["mandatory"],
                UNIFIED_SCHEMA["recommended"],
                UNIFIED_SCHEMA["optional"],
            ]:
                for field in section:
                    all_fields.append(field[0])

            with st.expander("Manu√°lis mapping szerkeszt√©se"):
                for csv_col in raw_df.columns:
                    current_mapping = initial_mapping.get(csv_col, "--Nincs--")
                    new_mapping = st.selectbox(
                        csv_col,
                        all_fields,
                        index=all_fields.index(current_mapping)
                        if current_mapping in all_fields
                        else 0,
                        key=f"manual_map_{csv_col}",
                    )
                    if new_mapping != "--Nincs--":
                        manual_corrections[csv_col] = new_mapping

            if manual_corrections:
                st.session_state.mapping.update(manual_corrections)

            st.subheader("üìã Adatok El≈ën√©zete (RAW)")
            st.dataframe(raw_df.head(10), use_container_width=True)

            st.session_state.platform_hint = (
                platform_hint if platform_hint != "Ismeretlen" else None
            )

        except Exception as e:
            st.error(f"‚ùå Hiba a f√°jl feldolgoz√°sakor: {str(e)}")

# ---------------------------------------------------------------------------
# TAB 2 ‚Äì Valid√°ci√≥
# ---------------------------------------------------------------------------
with tab2:
    if st.session_state.uploaded_data is not None:
        st.subheader("‚úÖ Adatok Normaliz√°l√°sa & Valid√°l√°sa")
        try:
            normalized_df = normalize_data(
                st.session_state.uploaded_data,
                st.session_state.mapping,
                platform_hint=getattr(st.session_state, "platform_hint", None),
            )
            st.session_state.normalized_data = normalized_df

            validation_issues = validate_data(normalized_df)

            if validation_issues:
                st.warning("### ‚ö†Ô∏è Valid√°ci√≥s Figyelmeztet√©sek")
                for issue in validation_issues:
                    st.warning(issue)
            else:
                st.success("### ‚úÖ Minden OK! Az adatok k√©szen √°llnak.")

            st.info(
                f"Normaliz√°lt adatok: {len(normalized_df)} sor √ó {len(normalized_df.columns)} oszlop"
            )
        except Exception as e:
            st.error(f"‚ùå Hiba a normaliz√°l√°s sor√°n: {str(e)}")
    else:
        st.info("El≈ësz√∂r t√∂ltsd fel az adatokat a 'üì• Felt√∂lt√©s & Mapping' f√ºl√∂n!")

# ---------------------------------------------------------------------------
# TAB 3 ‚Äì El≈ën√©zet
# ---------------------------------------------------------------------------
with tab3:
    if st.session_state.normalized_data is not None:
        st.subheader("üìä Normaliz√°lt Adatok El≈ën√©zete")
        try:
            df = st.session_state.normalized_data

            col1, col2, col3 = st.columns(3)
            with col1:
                if "spend" in df.columns:
                    st.metric("üí∞ Teljes K√∂lts√©g (HUF)", f"{df['spend'].sum():,.0f}")
            with col2:
                if "conversion_value" in df.columns:
                    st.metric(
                        "üíµ Konverzi√≥s √ârt√©k (HUF)",
                        f"{df['conversion_value'].sum():,.0f}",
                    )
            with col3:
                if "roas" in df.columns:
                    st.metric("üìà √Åtlag ROAS (x)", f"{df['roas'].mean():.2f}")

            st.subheader("Adatok T√°bl√°zat")
            df_display = df.copy()

            def fmt_int(x):
                if pd.isna(x):
                    return ""
                return f"{int(round(x)):,}".replace(",", " ")

            def fmt_huf(x):
                if pd.isna(x):
                    return ""
                return f"{int(round(x)):,}".replace(",", " ")

            def fmt_ctr(x):
                if pd.isna(x):
                    return ""
                return f"{x:.2f}".replace(".", ",") + "%"

            for col in ["conversions", "impressions", "clicks", "add_to_cart", "reach", "results"]:
                if col in df_display.columns:
                    df_display[col] = df_display[col].apply(fmt_int)

            if "frequency" in df_display.columns:
                df_display["frequency"] = df_display["frequency"].apply(
                    lambda x: "" if pd.isna(x) else f"{x:.4f}"
                )

            huf_cols = {
                "spend": "spend (HUF)",
                "conversion_value": "conversion_value (HUF)",
                "cpc": "cpc (HUF)",
                "cpa": "cpa (HUF, sz√°m√≠tott)",
                "conv_cost": "conv_cost (HUF)",
                "cost_per_addtocart": "cost_per_addtocart (HUF)",
                "adset_budget": "adset_budget (HUF)",
            }
            for src, dst in huf_cols.items():
                if src in df_display.columns:
                    df_display[dst] = df_display[src].apply(fmt_huf)
                    del df_display[src]

            if "ctr_percent" in df_display.columns:
                df_display["ctr_percent (%)"] = df_display["ctr_percent"].apply(fmt_ctr)
                del df_display["ctr_percent"]

            st.dataframe(df_display, use_container_width=True)
        except Exception as e:
            st.error(f"‚ùå Hiba az el≈ën√©zet sor√°n: {str(e)}")
    else:
        st.info("El≈ësz√∂r t√∂ltsd fel √©s normaliz√°ld az adatokat.")

# ---------------------------------------------------------------------------
# TAB 4 ‚Äì Ment√©s
# ---------------------------------------------------------------------------
with tab4:
    if st.session_state.normalized_data is not None:
        st.subheader("üíæ Adatok Export√°l√°sa")
        df = st.session_state.normalized_data

        col1, col2 = st.columns(2)
        with col1:
            csv = df.to_csv(index=False)
            st.download_button(
                "üì• CSV let√∂lt√©s",
                data=csv,
                file_name=f"hyper_normalized_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
            )
        with col2:
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
                df.to_excel(writer, index=False, sheet_name="Campaigns")
            st.download_button(
                "üì• Excel let√∂lt√©s",
                data=buffer.getvalue(),
                file_name=f"hyper_normalized_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            )
    else:
        st.info("El≈ësz√∂r t√∂ltsd fel √©s normaliz√°ld az adatokat.")

st.divider()
st.markdown(
    """
**HYPER App v3.7** | Neuromarketing ROAS Predictor  
F√°zis 1 k√©sz ‚Äì j√∂het a F√°zis 2 (Creative Analyzer + ML modell).
"""
)
